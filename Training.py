# -*- coding: utf-8 -*-
"""AI_Hackathon.ipynb

Automatically generated by Colaboratory.


!pip install split-folders

"""## ***Lets Split the train dataset into Train and Valid***"""

import splitfolders

input_folder = '/content/drive/MyDrive/India Academia Connect AI Hackathon/Dataset/train'

splitfolders.ratio(input_folder, output="Dataset", seed=42, ratio=(.8, .2), group_prefix=None)

"""## Import Libraries"""

import os 
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint

"""### Create Dataset Directory"""

train_dir = '/content/Dataset/train'
val_dir = '/content/Dataset/val'
test_dir = '/content/Dataset/Test'

# # To remove hidden .pynb_checkpoint file
# !rmdir /content/Dataset/val/.ipynb_checkpoints

from tensorflow.keras.preprocessing import image_dataset_from_directory

train_images = image_dataset_from_directory(train_dir,labels='inferred',
                                       label_mode='binary',interpolation='nearest',image_size=[224,224],batch_size=32,
                                       shuffle=True)

valid_images = image_dataset_from_directory(val_dir,labels='inferred',
                                       label_mode='binary',interpolation='nearest',image_size=[224,224],batch_size=32,
                                       shuffle=True)

"""### Visualize some Train images with labels"""

classes_train = train_images.class_names
plt.style.use('dark_background')
plt.figure(figsize=(10,10))
for img, label in train_images.take(1):
    for i in range(25):
        ax = plt.subplot(5,5,i+1)
        plt.imshow(img[i].numpy().astype('uint8'))
        plt.title(classes_train[int(label[i])])
        plt.axis('off')

"""### Visualize some Validation images with labels"""

classes_valid = valid_images.class_names
plt.style.use('dark_background')
plt.figure(figsize=(10,10))
for img, label in train_images.take(1):
    for i in range(25):
        ax = plt.subplot(5,5,i+1)
        plt.imshow(img[i].numpy().astype('uint8'))
        plt.title(classes_valid[int(label[i])])
        plt.axis('off')

"""# ***It's time for Data Augmentation ---> For Data Augmentation I am using random erasing method***"""

import numpy as np


def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):
    def eraser(input_img):
        img_h, img_w, img_c = input_img.shape
        p_1 = np.random.rand()

        if p_1 > p:
            return input_img

        while True:
            s = np.random.uniform(s_l, s_h) * img_h * img_w
            r = np.random.uniform(r_1, r_2)
            w = int(np.sqrt(s / r))
            h = int(np.sqrt(s * r))
            left = np.random.randint(0, img_w)
            top = np.random.randint(0, img_h)

            if left + w <= img_w and top + h <= img_h:
                break

        if pixel_level:
            c = np.random.uniform(v_l, v_h, (h, w, img_c))
        else:
            c = np.random.uniform(v_l, v_h)

        input_img[top:top + h, left:left + w, :] = c

        return input_img

    return eraser

train_datagen = ImageDataGenerator(rescale=1./255., preprocessing_function=get_random_eraser(v_l=0,v_h=1,pixel_level=True))

val_datagen = ImageDataGenerator(rescale=1./255.)

test_datagen = ImageDataGenerator(rescale=1./255.)

train_generator = train_datagen.flow_from_directory(train_dir,
                                                    class_mode='sparse',
                                                    target_size=(224,224),
                                                    batch_size=32)

val_generator = val_datagen.flow_from_directory(val_dir,
                                                class_mode='sparse',
                                                target_size=(224,224),
                                                batch_size=32)

test_generator = test_datagen.flow_from_directory(test_dir,
                                                  classes=['test'],
                                                  target_size=(224,224),
                                                  batch_size=1,shuffle=True)

"""### Lables for Dataset"""

labels = train_generator.class_indices
print(labels)

labels = dict((v,k) for k,v in labels.items())
print(labels)

print(f'There are total {len(labels)} number of classes present')

"""# Now it's time to import Resnet50 Model"""

resnet_base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)

"""### Model Architecture"""

for layer in resnet_base_model.layers:
  layer.trainable = True

for i, layer in enumerate(resnet_base_model.layers):
  print(i, layer.name, '-', layer.trainable)

model = Sequential()

model.add(resnet_base_model)

model.add(GlobalAveragePooling2D())

model.add(Flatten())

model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.3))
model.add(BatchNormalization())

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(BatchNormalization())

model.add(Dense(256, activation='relu'))
model.add(Dropout(0.3))
model.add(BatchNormalization())

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(BatchNormalization())

model.add(Dense(2, activation='softmax'))

model.summary()

"""### Compile the model"""

model.compile(loss='sparse_categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

"""## Callbacks"""

modelcheckpoint = tf.keras.callbacks.ModelCheckpoint('Best_Model_weights_1.h5', save_best_only=True, monitor='val_loss', mode='min')

tensorboard = tf.keras.callbacks.TensorBoard(log_dir='/content/logs')

CallBacks = [modelcheckpoint, tensorboard]

"""# Let's Start Training"""

model.fit(train_generator,
          validation_data= val_generator,
          epochs=15,
          callbacks=CallBacks)

pred = model.predict(test_generator)
pred

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing import image

dir_path = '/content/Dataset/Test/test'

for i in os.listdir(dir_path):
  inp = image.load_img(dir_path+'//'+i, target_size=(224,224))
  
  test_image=img_to_array(inp) 
  test_image=test_image/255.0
  prediction_image=np.array(test_image)
  prediction_image= np.expand_dims(test_image, axis=0)
    
  pred = model.predict(prediction_image)
  print(pred)
  value = np.argmax(pred)
  print(labels)
  print("Prediction: ", value)
  print("Prediction_class : ", labels[value])

  plt.imshow(inp)
  plt.show()

